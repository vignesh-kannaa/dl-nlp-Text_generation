{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMmteMmrMnazTnlle7g1pcv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"04_yNzDefHYA","executionInfo":{"status":"ok","timestamp":1675865602637,"user_tz":0,"elapsed":4268,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"markdown","source":["using shakespeare poem as training data"],"metadata":{"id":"YSB8AKV6uEN6"}},{"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PTz4IGvgNj9","executionInfo":{"status":"ok","timestamp":1675865602637,"user_tz":0,"elapsed":13,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"ff28ad11-e55e-4b7a-eb0c-6ccaabb54d4d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","print(f'Length: {len(text)}')\n","print(text[:250])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"du1D3IBSgnrT","executionInfo":{"status":"ok","timestamp":1675865602638,"user_tz":0,"elapsed":9,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"3e222572-fa8f-45d3-8224-112abb7aa853"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Length: 1115394\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"]}]},{"cell_type":"markdown","source":["Converting text to tokens, then to numbers <br>\n","Word embeddings can be done using Word2Vec or Bert.<br>\n","In this using keras Stringlookup, for character level prediction"],"metadata":{"id":"pdvWRJcitIY1"}},{"cell_type":"code","source":["vocab = sorted(set(text))\n","ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n","chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"],"metadata":{"id":"hWQaV-P-vPG8","executionInfo":{"status":"ok","timestamp":1675865606246,"user_tz":0,"elapsed":3615,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# testing sample data\n","\n","example_texts = ['abcdefg', 'xyz']\n","chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n","print(chars)\n","ids = ids_from_chars(chars)\n","print(ids)\n","\n","chars = chars_from_ids(ids)\n","print(chars)\n","\n","tf.strings.reduce_join(chars, axis=-1).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ygmkb0ospDN","executionInfo":{"status":"ok","timestamp":1675865606246,"user_tz":0,"elapsed":8,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"c52a0281-fcf1-4b19-a8e1-8caffb485f4f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>\n","<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>\n","<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>\n"]},{"output_type":"execute_result","data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"],"metadata":{"id":"pU8Pe-7Vssd_","executionInfo":{"status":"ok","timestamp":1675865606247,"user_tz":0,"elapsed":5,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqINjv_ct-Tx","executionInfo":{"status":"ok","timestamp":1675865608165,"user_tz":0,"elapsed":1922,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"821aea23-e053-4105-dced-d97ba5f3a170"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["divide the text into example sequences"],"metadata":{"id":"s1Z7TNQnx-eI"}},{"cell_type":"code","source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n","for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRivSultyDWx","executionInfo":{"status":"ok","timestamp":1675865608165,"user_tz":0,"elapsed":12,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"bf80b7df-01d9-4210-9126-193702132e5d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}]},{"cell_type":"markdown","source":["converting individual characters to sequences using batch"],"metadata":{"id":"JnlDkSzSyhMI"}},{"cell_type":"code","source":["seq_length = 100\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kQcbam2ykjU","executionInfo":{"status":"ok","timestamp":1675865608166,"user_tz":0,"elapsed":10,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"ad67fe1f-f130-4931-bc90-d1528e468855"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n"," b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n"," b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n"," b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n"," b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n"," b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n"," b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n"," b'o' b'u' b' '], shape=(101,), dtype=string)\n"]}]},{"cell_type":"code","source":["# visualising the data inside the batch\n","for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHDUnxvkyoa8","executionInfo":{"status":"ok","timestamp":1675865608166,"user_tz":0,"elapsed":8,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"7540fc56-19b2-4938-eddb-6c01ed87f86f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}]},{"cell_type":"markdown","source":["Formating input and output<br>\n","Text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\""],"metadata":{"id":"AdUR_DHVzOyK"}},{"cell_type":"code","source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"],"metadata":{"id":"4907XUBZyuVZ","executionInfo":{"status":"ok","timestamp":1675865608166,"user_tz":0,"elapsed":7,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["split_input_target(list(\"Hello\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyB3K9K_zaQh","executionInfo":{"status":"ok","timestamp":1675865608166,"user_tz":0,"elapsed":6,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"2d578461-50d8-4f7e-fa10-ac8200f9ceb3"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['H', 'e', 'l', 'l'], ['e', 'l', 'l', 'o'])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["dataset = sequences.map(split_input_target)\n","for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cu-UAQoqzdPs","executionInfo":{"status":"ok","timestamp":1675865608841,"user_tz":0,"elapsed":680,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"5b5d31a6-68b8-459e-9b64-7d4a1f9ec605"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}]},{"cell_type":"markdown","source":["Creating batches for training the data in the model"],"metadata":{"id":"LAEbxQjmz7S8"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 10000 # to shuffle the dataset\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTqfV9tMzsRP","executionInfo":{"status":"ok","timestamp":1675865608842,"user_tz":0,"elapsed":8,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"ee184f4b-5007-42f9-d411-3748d54c5d7f"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Building the Model"],"metadata":{"id":"xMFv4GqY0mzy"}},{"cell_type":"code","source":["vocab_size = len(ids_from_chars.get_vocabulary()) # Length of the vocabulary in StringLookup Layer\n","embedding_dim = 256\n","rnn_units = 1024"],"metadata":{"id":"Txn67JF1SpXk","executionInfo":{"status":"ok","timestamp":1675865608843,"user_tz":0,"elapsed":6,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x"],"metadata":{"id":"rOQZf_9m0LWW","executionInfo":{"status":"ok","timestamp":1675865608843,"user_tz":0,"elapsed":6,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model = MyModel(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"],"metadata":{"id":"ESPyfxkIBamt","executionInfo":{"status":"ok","timestamp":1675865608844,"user_tz":0,"elapsed":7,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vc-i8VYjSvSa","executionInfo":{"status":"ok","timestamp":1675865623778,"user_tz":0,"elapsed":20,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"7b6c9e71-8d2e-42fa-c751-fc4a6752eafa"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  16896     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4,022,850\n","Trainable params: 4,022,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam', \n","              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=tf.keras.metrics.BinaryAccuracy(name='accuracy'))\n","model.fit(dataset, epochs=30) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYOI4qSGTO4q","executionInfo":{"status":"ok","timestamp":1675866354623,"user_tz":0,"elapsed":487161,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"27859af2-f34b-48a7-9543-bba36813d7b4"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","172/172 [==============================] - 12s 54ms/step - loss: 1.1719\n","Epoch 2/30\n","172/172 [==============================] - 11s 55ms/step - loss: 1.1229\n","Epoch 3/30\n","172/172 [==============================] - 11s 55ms/step - loss: 1.0759\n","Epoch 4/30\n","172/172 [==============================] - 11s 56ms/step - loss: 1.0282\n","Epoch 5/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.9766\n","Epoch 6/30\n","172/172 [==============================] - 12s 54ms/step - loss: 0.9224\n","Epoch 7/30\n","172/172 [==============================] - 12s 55ms/step - loss: 0.8675\n","Epoch 8/30\n","172/172 [==============================] - 12s 55ms/step - loss: 0.8120\n","Epoch 9/30\n","172/172 [==============================] - 12s 55ms/step - loss: 0.7592\n","Epoch 10/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.7109\n","Epoch 11/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.6639\n","Epoch 12/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.6255\n","Epoch 13/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.5920\n","Epoch 14/30\n","172/172 [==============================] - 12s 55ms/step - loss: 0.5625\n","Epoch 15/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.5365\n","Epoch 16/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.5153\n","Epoch 17/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.5002\n","Epoch 18/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.4887\n","Epoch 19/30\n","172/172 [==============================] - 12s 54ms/step - loss: 0.4774\n","Epoch 20/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.4670\n","Epoch 21/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.4587\n","Epoch 22/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.4527\n","Epoch 23/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.4455\n","Epoch 24/30\n","172/172 [==============================] - 12s 55ms/step - loss: 0.4412\n","Epoch 25/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.4383\n","Epoch 26/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.4337\n","Epoch 27/30\n","172/172 [==============================] - 13s 58ms/step - loss: 0.4319\n","Epoch 28/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.4323\n","Epoch 29/30\n","172/172 [==============================] - 11s 54ms/step - loss: 0.4279\n","Epoch 30/30\n","172/172 [==============================] - 11s 55ms/step - loss: 0.4232\n"]}]},{"cell_type":"code","source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"],"metadata":{"id":"x-v3xXfUXODR","executionInfo":{"status":"ok","timestamp":1675866391792,"user_tz":0,"elapsed":594,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"],"metadata":{"id":"yyawfMgrXSJL","executionInfo":{"status":"ok","timestamp":1675866396947,"user_tz":0,"elapsed":877,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w-IH4RQXYmQ","executionInfo":{"status":"ok","timestamp":1675867290261,"user_tz":0,"elapsed":3795,"user":{"displayName":"vignesh kannaa","userId":"01064752481468640964"}},"outputId":"118c0e5d-af37-49b8-b6db-87caa074d593"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\n","Stay, you;--and through both gripe of this: I speak\n","from other houses, or man, whose every powers\n","But what she wounds upon this holy present,\n","Ne'er should they woe can list and swift light.\n","Boldmence have I lend thee than I would not\n","Which in my love but him up in session, in one land,\n","That weigh'd put in the northing season: then,\n","After this in a reply, do not once peer,\n","Madam, if design good estimate Haste,\n","And dares your lady's word, and hasty as there.\n","\n","TONCANIO:\n","Thou hast the very nark indeed\n","And the ear of mine or how we mean but his hands.\n","\n","GLOUCESTER:\n","How does the Duke of Herciuse, his name to this take.\n","\n","POMPEY:\n","Why, very well; I think you would he was by him,\n","He shall be Viennant's live, sweet masters, I hear him\n","sing: the duke shall know our brother, to the sea?\n","I now remains the vein work good night!\n","And, quink, and thus I cursed but by the world,\n","Whom thou loves any in the chine.\n","\n","CAPULET:\n","How long is now rice? I have been faithful quest;\n","Mine honour! not by the king, and \n","\n","________________________________________________________________________________\n","\n","Run time: 2.8564867973327637\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"evivHPh_eQ7r"},"execution_count":null,"outputs":[]}]}